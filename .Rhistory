plot(apply(array.lsk,c(1,3),sum),nlk)
lines(c(0,1000),c(0,1000))
#look at stuff to make sure it makes sense
phi.estim=nks/matrix(rowSums(nks),ncommun,nspp)
plot(phi.true,phi.estim)
nks.true=nks
library(MCMCpack)
library('coda')
plot(res$llk[1:ngibbs],type='l')
nburn=100
plot(res$llk[nburn:ngibbs],type='l')
#calculate effective sample size
effectiveSize(mcmc(res$betas[nburn:ngibbs,]))
plot(res$betas[nburn:ngibbs,1],type='l')
plot(res$NBN,type='l')
compare1=function(estim,true){
rango=range(c(true,estim))
plot(true,estim,ylim=rango,xlim=rango)
lines(rango,rango,col='red',lwd=2)
}
k=res$betas[ngibbs,]
nparam=ncol(xmat)
k1=matrix(k,nparam,ncomm); round(k1,2)
ordem=rep(NA,ncomm)
for (i in 2:nparam){
ordem[i-1]=which(k1[i,]==max(k1[i,]))
}
round(k1[,ordem],2)
image(k1[,ordem])
#look at nlk
par(mfrow=c(1,1))
tmp=matrix(res$nlk[ngibbs,],nloc,ncomm);
boxplot(tmp)
compare1(estim=jitter(tmp[,ordem]),true=jitter(nlk.true))
#look at betas
k=matrix(res$betas[ngibbs,],nparam,ncomm)
compare1(estim=k[,ordem],true=betas.true)
#look at phi
tmp=matrix(res$phi[ngibbs,],ncomm,nspp)
tmp1=tmp[ordem,]
compare1(estim=tmp1,true=phi.true)
rm(list=ls(all=TRUE))
library(MCMCpack)
library('Rcpp')
set.seed(10)
#get data
setwd('U:\\GIT_models\\git_LDA_MS')
dat=read.csv('fake data.csv',as.is=T)
xmat=data.matrix(read.csv('fake data xmat.csv',as.is=T))
# xmat=xmat[,1:2]
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
#get array.lsk
tmp=read.csv('array lsk.csv',as.is=T)
ncomm.init=length(tmp$V1)/(nspp*nloc); ncomm.init
array.lsk.init=array(tmp$V1,dim=c(nloc,nspp,ncomm.init))
#get phi
phi.init=data.matrix(read.csv('phi step1.csv',as.is=T))
#basic settings
ngibbs=1000
nburn=ngibbs/2
#priors
phi.prior=0.01
var.betas=c(10,rep(10,ncol(xmat)-1))
gamma=0.1
nlk=apply(array.lsk.init,c(1,3),sum)
theta1=nlk/apply(nlk,1,sum)
par(mfrow=c(1,1),mar=c(3,3,1,1))
boxplot(theta1)
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('LDA cov main function.R')
source('LDA cov aux functions.R')
sourceCpp('LDA_cov_aux1_cpp.cpp')
sourceCpp('slice_betas.cpp')
sourceCpp('slice_NBN.cpp')
ncomm=4
res=gibbs.LDA.cov(ncomm=ncomm,ngibbs=ngibbs,y=y,xmat=xmat,
phi.prior=phi.prior,array.lsk.init=array.lsk.init,
var.betas=var.betas,estimate.phi=T,
phi.init=phi.init)
setwd('U:\\GIT_models\\git_LDA_MS')
source('LDA cov main function.R')
source('LDA cov aux functions.R')
sourceCpp('LDA_cov_aux1_cpp.cpp')
sourceCpp('slice_betas.cpp')
sourceCpp('slice_NBN.cpp')
setwd('U:\\GIT_models\\git_LDA_MS')
source('LDA cov main function.R')
source('LDA cov aux functions.R')
sourceCpp('LDA_cov_aux1_cpp.cpp')
sourceCpp('slice_betas.cpp')
sourceCpp('slice_NBN.cpp')
ncomm=4
res=gibbs.LDA.cov(ncomm=ncomm,ngibbs=ngibbs,y=y,xmat=xmat,
phi.prior=phi.prior,array.lsk.init=array.lsk.init,
var.betas=var.betas,estimate.phi=T,
phi.init=phi.init)
library(MCMCpack)
library('coda')
plot(res$llk[1:ngibbs],type='l')
nburn=200
plot(res$llk[nburn:ngibbs],type='l')
effectiveSize(mcmc(res$betas[nburn:ngibbs,]))
plot(res$betas[nburn:ngibbs,1],type='l')
plot(res$NBN,type='l')
compare1=function(estim,true){
rango=range(c(true,estim))
plot(true,estim,ylim=rango,xlim=rango)
lines(rango,rango,col='red',lwd=2)
}
k=res$betas[ngibbs,]
nparam=ncol(xmat)
k1=matrix(k,nparam,ncomm); round(k1,2)
ordem=rep(NA,ncomm)
for (i in 2:nparam){
ordem[i-1]=which(k1[i,]==max(k1[i,]))
}
round(k1[,ordem],2)
image(k1[,ordem])
#look at nlk
par(mfrow=c(1,1))
tmp=matrix(res$nlk[ngibbs,],nloc,ncomm);
boxplot(tmp)
compare1(estim=jitter(tmp[,ordem]),true=jitter(nlk.true))
library(MCMCpack)
set.seed(201)
nloc=2000
nspp=200
ncommun=4
#design matrix
xmat=matrix(runif(nloc*ncommun,min=-1,max=3),nloc,ncommun)
#pure sites
tmp=matrix(-3,ncommun,ncommun)
diag(tmp)=2
num1=floor(nloc/ncommun)
for (i in 1:300){
seq1=(ncommun*(i-1)+1):(ncommun*i)
xmat[seq1,]=tmp
}
image(xmat)
xmat=cbind(1,xmat)
#parameters
b0=log(runif(ncommun,min=5,max=8))
betas.true=betas=rbind(b0,diag(1,ncommun))
#get means
media.true=media=exp(xmat%*%betas); range(media)
head(media)
#generate N_lk
par(mfrow=c(1,1),mar=rep(4,4))
nlk=matrix(NA,nloc,ncommun)
NBN=20 #when this is large, we get into areas with relatively flat loglikel, giving trouble to the slice sampler
for (i in 1:ncommun){
nlk[,i]=rnbinom(nloc,mu=media[,i],size=NBN)
}
nlk.true=nlk; boxplot(nlk)
soma=apply(nlk,1,sum); sum(soma==0)
theta.true=theta=nlk/soma; apply(theta,1,sum);
boxplot(theta); apply(theta,2,range); apply(theta>0.95,2,mean)
nl=apply(nlk,1,sum)
hist(nl)
sum(nl)
plot(media,nlk)
#generate phi:
#- assume that each species is strongly present in a single group
#- Avoid very rare species (species that are almost never present)
tmp=matrix(0.05,ncommun,nspp)
base=nspp/ncommun
margin1=floor(base*0.2)
seq1=c(seq(from=1,to=nspp,by=base),nspp-margin1)
for (i in 1:(length(seq1)-1)){ #add some zeroes
seq2=seq1[i]:(seq1[i+1]+margin1)
tmp[i,seq2]=1
}
phi=tmp/matrix(rowSums(tmp),ncommun,nspp) #re-scale to make sure it sums to 1
phi.true=phi
# round(phi[,1:20],2)
# table(round(phi,2))
unique(rowSums(phi))
phi.true=phi
image(phi)
#generate actual observations y
array.lsk=array(0,dim=c(nloc,nspp,ncommun))
for (i in 1:nloc){
for (k in 1:ncommun){
array.lsk[i,,k]=rmultinom(1,size=nlk[i,k],prob=phi[k,])
}
}
array.lsk.true=array.lsk
y=apply(array.lsk,c(1,2),sum)
nks=t(apply(array.lsk,c(2,3),sum))
image(y)
phi.estim=nks/rowSums(nks)
rango=range(c(phi,phi.estim))
plot(phi,phi.estim,ylim=rango,xlim=rango)
lines(rango,rango,col='red')
#checking if it makes sense
plot(apply(array.lsk,c(1,3),sum),nlk)
lines(c(0,1000),c(0,1000))
#look at stuff to make sure it makes sense
phi.estim=nks/matrix(rowSums(nks),ncommun,nspp)
plot(phi.true,phi.estim)
nks.true=nks
par(mfrow=c(1,1))
tmp=matrix(res$nlk[ngibbs,],nloc,ncomm);
boxplot(tmp)
compare1(estim=jitter(tmp[,ordem]),true=jitter(nlk.true))
#look at betas
k=matrix(res$betas[ngibbs,],nparam,ncomm)
compare1(estim=k[,ordem],true=betas.true)
#look at phi
tmp=matrix(res$phi[ngibbs,],ncomm,nspp)
tmp1=tmp[ordem,]
compare1(estim=tmp1,true=phi.true)
rm(list=ls(all=TRUE))
library(MCMCpack)
library('Rcpp')
set.seed(10)
#get data
setwd('U:\\GIT_models\\git_LDA_MS')
dat=read.csv('fake data.csv',as.is=T)
xmat=data.matrix(read.csv('fake data xmat.csv',as.is=T))
# xmat=xmat[,1:2]
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
#get array.lsk
tmp=read.csv('array lsk.csv',as.is=T)
ncomm.init=length(tmp$V1)/(nspp*nloc); ncomm.init
array.lsk.init=array(tmp$V1,dim=c(nloc,nspp,ncomm.init))
#get phi
phi.init=data.matrix(read.csv('phi step1.csv',as.is=T))
#basic settings
ngibbs=1000
nburn=ngibbs/2
#priors
phi.prior=0.01
var.betas=c(10,rep(10,ncol(xmat)-1))
gamma=0.1
#----------------------------------------------------------
#determine optimal number of groups
nlk=apply(array.lsk.init,c(1,3),sum)
theta1=nlk/apply(nlk,1,sum)
par(mfrow=c(1,1),mar=c(3,3,1,1))
boxplot(theta1)
#----------------------------------------------------------
#LDA with covariates
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('LDA cov main function.R')
source('LDA cov aux functions.R')
sourceCpp('LDA_cov_aux1_cpp.cpp')
sourceCpp('slice_betas.cpp')
sourceCpp('slice_NBN.cpp')
#re-estimate phi
ncomm=4
res=gibbs.LDA.cov(ncomm=ncomm,ngibbs=ngibbs,y=y,xmat=xmat,
phi.prior=phi.prior,array.lsk.init=array.lsk.init,
var.betas=var.betas,phi.init=phi.init,estimate.phi=F)
rm(list=ls(all=TRUE))
library(MCMCpack)
library('Rcpp')
set.seed(10)
#get data
setwd('U:\\GIT_models\\git_LDA_MS')
dat=read.csv('fake data.csv',as.is=T)
xmat=data.matrix(read.csv('fake data xmat.csv',as.is=T))
# xmat=xmat[,1:2]
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
#get array.lsk
tmp=read.csv('array lsk.csv',as.is=T)
ncomm.init=length(tmp$V1)/(nspp*nloc); ncomm.init
array.lsk.init=array(tmp$V1,dim=c(nloc,nspp,ncomm.init))
#get phi
phi.init=data.matrix(read.csv('phi step1.csv',as.is=T))
#basic settings
ngibbs=1000
nburn=ngibbs/2
#priors
phi.prior=0.01
var.betas=c(10,rep(10,ncol(xmat)-1))
gamma=0.1
#----------------------------------------------------------
#determine optimal number of groups
nlk=apply(array.lsk.init,c(1,3),sum)
theta1=nlk/apply(nlk,1,sum)
par(mfrow=c(1,1),mar=c(3,3,1,1))
boxplot(theta1)
#----------------------------------------------------------
#LDA with covariates
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('LDA cov main function.R')
source('LDA cov aux functions.R')
sourceCpp('LDA_cov_aux1_cpp.cpp')
sourceCpp('slice_betas.cpp')
sourceCpp('slice_NBN.cpp')
#re-estimate phi
ncomm=4
res=gibbs.LDA.cov(ncomm=ncomm,ngibbs=ngibbs,y=y,xmat=xmat,
phi.prior=phi.prior,array.lsk.init=array.lsk.init,
var.betas=var.betas,phi.init=phi.init,estimate.phi=F)
library(MCMCpack)
set.seed(201)
nloc=2000
nspp=200
ncommun=4
#design matrix
xmat=matrix(runif(nloc*ncommun,min=-1,max=3),nloc,ncommun)
#pure sites
tmp=matrix(-3,ncommun,ncommun)
diag(tmp)=2
num1=floor(nloc/ncommun)
for (i in 1:300){
seq1=(ncommun*(i-1)+1):(ncommun*i)
xmat[seq1,]=tmp
}
image(xmat)
xmat=cbind(1,xmat)
#parameters
b0=log(runif(ncommun,min=5,max=8))
betas.true=betas=rbind(b0,diag(1,ncommun))
#get means
media.true=media=exp(xmat%*%betas); range(media)
head(media)
#generate N_lk
par(mfrow=c(1,1),mar=rep(4,4))
nlk=matrix(NA,nloc,ncommun)
NBN=20 #when this is large, we get into areas with relatively flat loglikel, giving trouble to the slice sampler
for (i in 1:ncommun){
nlk[,i]=rnbinom(nloc,mu=media[,i],size=NBN)
}
nlk.true=nlk; boxplot(nlk)
soma=apply(nlk,1,sum); sum(soma==0)
theta.true=theta=nlk/soma; apply(theta,1,sum);
boxplot(theta); apply(theta,2,range); apply(theta>0.95,2,mean)
nl=apply(nlk,1,sum)
hist(nl)
sum(nl)
plot(media,nlk)
#generate phi:
#- assume that each species is strongly present in a single group
#- Avoid very rare species (species that are almost never present)
tmp=matrix(0.05,ncommun,nspp)
base=nspp/ncommun
margin1=floor(base*0.2)
seq1=c(seq(from=1,to=nspp,by=base),nspp-margin1)
for (i in 1:(length(seq1)-1)){ #add some zeroes
seq2=seq1[i]:(seq1[i+1]+margin1)
tmp[i,seq2]=1
}
phi=tmp/matrix(rowSums(tmp),ncommun,nspp) #re-scale to make sure it sums to 1
phi.true=phi
# round(phi[,1:20],2)
# table(round(phi,2))
unique(rowSums(phi))
phi.true=phi
image(phi)
#generate actual observations y
array.lsk=array(0,dim=c(nloc,nspp,ncommun))
for (i in 1:nloc){
for (k in 1:ncommun){
array.lsk[i,,k]=rmultinom(1,size=nlk[i,k],prob=phi[k,])
}
}
array.lsk.true=array.lsk
y=apply(array.lsk,c(1,2),sum)
nks=t(apply(array.lsk,c(2,3),sum))
image(y)
phi.estim=nks/rowSums(nks)
rango=range(c(phi,phi.estim))
plot(phi,phi.estim,ylim=rango,xlim=rango)
lines(rango,rango,col='red')
#checking if it makes sense
plot(apply(array.lsk,c(1,3),sum),nlk)
lines(c(0,1000),c(0,1000))
#look at stuff to make sure it makes sense
phi.estim=nks/matrix(rowSums(nks),ncommun,nspp)
plot(phi.true,phi.estim)
nks.true=nks
library(MCMCpack)
library('coda')
plot(res$llk[1:ngibbs],type='l')
nburn=200
plot(res$llk[nburn:ngibbs],type='l')
effectiveSize(mcmc(res$betas[nburn:ngibbs,]))
plot(res$betas[nburn:ngibbs,1],type='l')
plot(res$NBN,type='l')
compare1=function(estim,true){
rango=range(c(true,estim))
plot(true,estim,ylim=rango,xlim=rango)
lines(rango,rango,col='red',lwd=2)
}
k=res$betas[ngibbs,]
nparam=ncol(xmat)
k1=matrix(k,nparam,ncomm); round(k1,2)
ordem=rep(NA,ncomm)
for (i in 2:nparam){
ordem[i-1]=which(k1[i,]==max(k1[i,]))
}
round(k1[,ordem],2)
image(k1[,ordem])
#look at nlk
par(mfrow=c(1,1))
tmp=matrix(res$nlk[ngibbs,],nloc,ncomm);
boxplot(tmp)
compare1(estim=jitter(tmp[,ordem]),true=jitter(nlk.true))
#look at betas
k=matrix(res$betas[ngibbs,],nparam,ncomm)
compare1(estim=k[,ordem],true=betas.true)
#look at phi
tmp=matrix(res$phi[ngibbs,],ncomm,nspp)
tmp1=tmp[ordem,]
compare1(estim=tmp1,true=phi.true)
library(ldacov)
library(ldacov)
data("sim_data")
set.seed(1)
lda_no_covariates=gibbs.LDA(y=sim_data$y,
ncomm=10,
ngibbs=1000,
nburn=500,
psi=0.01,
gamma=0.1)
plot(lda_no_covariates$llk,type='l',xlab='Iterations',ylab='Log-likelihood')
array.lsk.init=lda_no_covariates$array.lsk
nlk=apply(array.lsk.init,c(1,3),sum)
theta=nlk/apply(nlk,1,sum)
colnames(theta)=paste0('Cluster',1:10)
rownames(theta)=paste0('Unit',1:nrow(sim_data$y))
head(round(theta,2))
boxplot(theta,ylab=expression(theta),xlab='Clusters',ylim=c(0,1))
cumsum1=cumsum(colSums(theta,na.rm=TRUE)/nrow(sim_data$y))
cumsum1[1:4]
lda_with_covariates <- gibbs.LDA.cov(ncomm=4,
ngibbs=1000,
y=sim_data$y,
xmat=sim_data$xmat,
phi.prior=0.01,
array.lsk.init=lda_no_covariates$array.lsk,
var.betas=rep(100,ncol(sim_data$xmat)),
phi.init=lda_no_covariates$phi,
estimate.phi=FALSE)
plot(lda_with_covariates$llk,type='l',xlab="iterations",ylab='log-likelihood')
seq1=100:1000
tmp=matrix(colMeans(lda_with_covariates$nlk[seq1,]),nrow=nrow(sim_data$y),ncol=4)
theta <- tmp/rowSums(tmp)
colnames(theta)=paste0('Cluster',1:4)
rownames(theta)=paste0('Units',1:nrow(sim_data$y))
head(round(theta,2))
data <- expand.grid(X=1:nrow(sim_data$y), Y=1:4)
data$proportion <- as.vector(theta)
library(ggplot2)
ggplot(data, aes(X, Y, fill= proportion)) + geom_tile() +
scale_fill_gradient(low="green", high="darkblue",na.value="green") +
labs(x = "Units") + labs(y = "Cluster distribution") +
labs(fill = " ")+theme_minimal() +
ggtitle("Estimated Theta matrix")
phi <- matrix(colMeans(lda_with_covariates$phi[seq1,]),nrow=4,ncol=ncol(sim_data$y))
rownames(phi)=paste0('Cluster',1:4)
colnames(phi)=paste0('Category',1:ncol(sim_data$y))
head(round(phi[,1:10],2))
data <- expand.grid(X=1:ncol(sim_data$y), Y=1:4)
data$proportion <- as.vector(phi)
ggplot(data, aes(X, Y, fill= proportion)) + geom_tile() +
scale_fill_gradient(low="green", high="darkblue",na.value="green") +
labs(x = "Category distribution") + labs(y = "Cluster") +
labs(fill = " ")+theme_minimal()+
ggtitle("Estimated Phi matrix")
phi.max=matrix(NA,nrow=4,ncol=ncol(sim_data$y))
for (i in 1:4){phi.max[i,]=apply(phi[-i,], 2, max)}
results=phi/phi.max
colnames(results)=colnames(phi)
rownames(results)=rownames(phi)
head(round(results[,1:10],2))
max_categ_cluster=apply(phi/phi.max, 1, function(x) names(sort(x,decreasing=TRUE)))
head(max_categ_cluster)
tmp=colMeans(lda_with_covariates$betas[seq1,])
betas=matrix(tmp,ncol=4)
colnames(betas)=paste0('Cluster',1:4)
rownames(betas)=paste0('Coefficients',1:nrow(betas))
head(round(betas,3))
library(reshape2)
library(ggridges)
number <- 1:length(seq1)
aux1 <- data.frame(number,lda_with_covariates$betas[seq1,])
aux2 <- melt(aux1, id=c("number"))
aux2$variable <- (gsub("X", "", aux2$variable))
ggplot(aux2, aes(x = value, y = variable, fill = variable)) +
geom_density_ridges(size=0.4) +
theme_ridges() +
theme(legend.position = "none") +
xlab("Value") +
ylab("Betas") +
theme(axis.title.y=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank(),
axis.title.x=element_blank())
phi.max=matrix(NA,nrow=4,ncol=ncol(sim_data$y))
for (i in 1:4){phi.max[i,]=apply(phi[-i,], 2, max)}
results=phi/phi.max
colnames(results)=colnames(phi)
rownames(results)=rownames(phi)
head(round(results[,1:10],2))
tmp=colMeans(lda_with_covariates$betas[seq1,])
betas=matrix(tmp,ncol=4)
colnames(betas)=paste0('Cluster',1:4)
rownames(betas)=paste0('Coefficients',1:nrow(betas))
head(round(betas,3))
