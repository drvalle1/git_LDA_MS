sum(dbeta(x,a1,a2,log=T))+dgamma(a1,0.5,0.5,log=T)+dgamma(a2,0.5,0.5,log=T)
}
#MH
niter=1000
sd.jump=0.1
a1=0.1
a1.store=rep(NA,niter)
for (i in 1:niter){
a1.new=rnorm(1,mean=a1,sd=sd.jump)
a1.new=ifelse(a1.new<0,abs(a1.new),a1.new)
target.new=log.target(a1=a1.new,a2=a2,x=x)
target.old=log.target(a1=a1    ,a2=a2,x=x)
pthresh=exp(target.new-target.old)
if (runif(1)<pthresh) a1=a1.new
a1.store[i]=a1
}
plot(density(a1.store),type='l')
plot(a1.store,type='l')
rm(list=ls(all=TRUE))
set.seed(1)
#simulated data
nobs=100
a1=1
a2=2
x=rbeta(nobs,a1,a2)
log.target=function(a1,a2,x){
sum(dbeta(x,a1,a2,log=T))+dgamma(a1,0.5,0.5,log=T)+dgamma(a2,0.5,0.5,log=T)
}
#MH
niter=1000
sd.jump=1
a1=0.1
a1.store=rep(NA,niter)
for (i in 1:niter){
a1.new=rnorm(1,mean=a1,sd=sd.jump)
a1.new=ifelse(a1.new<0,abs(a1.new),a1.new)
target.new=log.target(a1=a1.new,a2=a2,x=x)
target.old=log.target(a1=a1    ,a2=a2,x=x)
pthresh=exp(target.new-target.old)
if (runif(1)<pthresh) a1=a1.new
a1.store[i]=a1
}
plot(a1.store,type='l')
plot(density(a1.store),type='l')
plot(a1.store,type='l')
rm(list=ls(all=TRUE))
set.seed(1)
#simulated data
nobs=100
a1=1
a2=2
x=rbeta(nobs,a1,a2)
log.target=function(a1,a2,x){
sum(dbeta(x,a1,a2,log=T))+dgamma(a1,0.5,0.5,log=T)+dgamma(a2,0.5,0.5,log=T)
}
#MH
niter=1000
sd.jump=2
a1=0.1
a1.store=rep(NA,niter)
for (i in 1:niter){
a1.new=rnorm(1,mean=a1,sd=sd.jump)
a1.new=ifelse(a1.new<0,abs(a1.new),a1.new) #reflect proposal if negative
target.new=log.target(a1=a1.new,a2=a2,x=x)
target.old=log.target(a1=a1    ,a2=a2,x=x)
pthresh=exp(target.new-target.old)
if (runif(1)<pthresh) a1=a1.new
a1.store[i]=a1
}
plot(a1.store,type='l')
rm(list=ls(all=TRUE))
set.seed(1)
#simulated data
nobs=100
a1=1
a2=2
x=rbeta(nobs,a1,a2)
log.target=function(a1,a2,x){
sum(dbeta(x,a1,a2,log=T))+dgamma(a1,0.5,0.5,log=T)+dgamma(a2,0.5,0.5,log=T)
}
#MH
niter=1000
sd.jump=0.0001
a1=0.1
a1.store=rep(NA,niter)
for (i in 1:niter){
a1.new=rnorm(1,mean=a1,sd=sd.jump)
a1.new=ifelse(a1.new<0,abs(a1.new),a1.new) #reflect proposal if negative
target.new=log.target(a1=a1.new,a2=a2,x=x)
target.old=log.target(a1=a1    ,a2=a2,x=x)
pthresh=exp(target.new-target.old)
if (runif(1)<pthresh) a1=a1.new
a1.store[i]=a1
}
plot(a1.store,type='l')
library(circular)
?dvonmises
data1 <- rvonmises(1000, circular(0), 10, control.circular=list(units="degrees"))
plot(data1)
ff <- function(x) dvonmises(x, mu=circular(pi), kappa=10)
curve.circular(ff, join=TRUE, xlim=c(-2.3, 1),
main="Density of a VonMises Distribution \n mu=pi, kappa=10")
x=seq(from=0,to=2*pi,length.out=1000)
y=dvonmises(x, mu=circular(pi), kappa=10)
plot(x,y)
x=seq(from=0,to=2*pi,length.out=1000)
y=dvonmises(x, mu=circular(2*pi*0.99), kappa=10)
plot(x,y)
rm(list=ls(all=TRUE))
library(MCMCpack)
set.seed(13)
nloc=3000
nspp=150
ncommun=5
#design matrix
xmat=matrix(runif(nloc*ncommun,min=-1,max=3),nloc,ncommun)
#pure sites
tmp=matrix(-3,ncommun,ncommun)
diag(tmp)=2
num1=floor(nloc/ncommun)
for (i in 1:300){
seq1=(ncommun*(i-1)+1):(ncommun*i)
xmat[seq1,]=tmp
}
image(xmat)
xmat=cbind(1,xmat)
#parameters
b0=log(runif(ncommun,min=5,max=8))
betas.true=betas=rbind(b0,diag(1,ncommun))
#get means
media.true=media=exp(xmat%*%betas); range(media)
head(media)
#generate N_lk
par(mfrow=c(1,1),mar=rep(4,4))
nlk=matrix(NA,nloc,ncommun)
NBN=10 #when this is large, we get into areas with relatively flat loglikel, giving trouble to the slice sampler
for (i in 1:ncommun){
nlk[,i]=rnbinom(nloc,mu=media[,i],size=NBN)
}
nlk.true=nlk; boxplot(nlk)
soma=apply(nlk,1,sum); sum(soma==0)
theta.true=theta=nlk/soma; apply(theta,1,sum);
boxplot(theta); apply(theta,2,range); apply(theta>0.95,2,mean)
nl=apply(nlk,1,sum)
hist(nl)
sum(nl)
plot(media,nlk)
#generate phi:
#- assume that each species is strongly present in a single group
#- Avoid very rare species (species that are almost never present)
tmp=matrix(0,ncommun,nspp)
base=nspp/ncommun
margin1=floor(base*0.2)
seq1=c(seq(from=1,to=nspp,by=base),nspp-margin1)
for (i in 1:(length(seq1)-1)){ #add some zeroes
seq2=seq1[i]:(seq1[i+1]+margin1)
tmp[i,seq2]=1
}
phi=tmp/matrix(rowSums(tmp),ncommun,nspp) #re-scale to make sure it sums to 1
phi.true=phi
# round(phi[,1:20],2)
# table(round(phi,2))
unique(rowSums(phi))
phi.true=phi
image(phi)
#generate actual observations y
array.lsk=array(0,dim=c(nloc,nspp,ncommun))
for (i in 1:nloc){
for (k in 1:ncommun){
array.lsk[i,,k]=rmultinom(1,size=nlk[i,k],prob=phi[k,])
}
}
array.lsk.true=array.lsk
y=apply(array.lsk,c(1,2),sum)
nks=t(apply(array.lsk,c(2,3),sum))
image(y)
phi.estim=nks/rowSums(nks)
rango=range(c(phi,phi.estim))
plot(phi,phi.estim,ylim=rango,xlim=rango)
lines(rango,rango,col='red')
#checking if it makes sense
plot(apply(array.lsk,c(1,3),sum),nlk)
lines(c(0,1000),c(0,1000))
#look at stuff to make sure it makes sense
phi.estim=nks/matrix(rowSums(nks),ncommun,nspp)
plot(phi.true,phi.estim)
nks.true=nks
#export results
setwd('U:\\GIT_models\\git_LDA_MS')
nome='fake data.csv'
colnames(y)=paste('spp',1:nspp,sep='')
rownames(y)=paste('loc',1:nloc,sep='')
write.csv(y,nome,row.names=F)
nome='fake data xmat.csv'
write.csv(xmat,nome,row.names=F)
rm(list=ls(all=TRUE))
library(MCMCpack)
library('Rcpp')
library('RcppArmadillo')
set.seed(33)
#get data
setwd('U:\\GIT_models\\git_LDA_MS')
dat=read.csv('fake data.csv',as.is=T)
xmat=data.matrix(read.csv('fake data xmat.csv',as.is=T))
y=data.matrix(dat)
#basic settings
ncomm.init=10
ngibbs=1000
nburn=ngibbs/2
#priors
psi=0.01
gamma=0.1
#----------------------------------------------------------
#run LDA no covariates to get initial values
#get functions
setwd('U:\\GIT_models\\git_LDA_abundance')
source('gibbs functions.R')
source('LDA.abundance main function.R')
sourceCpp('aux1.cpp')
res=LDA.abundance(y=y,ncomm=ncomm.init,ngibbs=ngibbs,nburn=nburn,psi=psi,gamma=gamma)
nloc=nrow(y)
nspp=ncol(y)
array.lsk.init=res$array.lsk
#look at convergence
plot(res$llk,type='l')
#determine optimal number of groups
nlk=apply(array.lsk.init,c(1,3),sum)
theta=nlk/apply(nlk,1,sum)
par(mfrow=c(1,1),mar=c(3,3,1,1))
boxplot(theta)
ncomm=5
prop=apply(theta>0.99,2,sum,na.rm=T) #see which communities are never above 0.8
which(prop!=0)
cond=prop!=0
ncomm=sum(cond)
#re-distribute individuals within array.lsk.init that are in eliminated communities
array.lsk=array.lsk.init[,,cond]
for (i in 1:nloc){
for (j in 1:nspp){
tmp=array.lsk.init[i,j,!cond]
n=sum(tmp)
if (n>0){
z=rmultinom(1,size=n,prob=rep(1/ncomm,ncomm))
array.lsk[i,j,]=array.lsk[i,j,]+z
}
}
}
#export results
dat1=matrix(array.lsk,nloc*nspp*ncomm,1)
setwd('U:\\GIT_models\\git_LDA_MS')
write.csv(dat1,'array lsk.csv',row.names=F)
#output posterior for phi
plot(res$llk,type='l')
length(res$llk)
plot(res$llk,type='l')
nburn=400
seq1=nburn:length(res$llk)
plot(res$llk[seq1],type='l')
library(MCMCpack)
set.seed(13)
nloc=3000
nspp=150
ncommun=5
#design matrix
xmat=matrix(runif(nloc*ncommun,min=-1,max=3),nloc,ncommun)
#pure sites
tmp=matrix(-3,ncommun,ncommun)
diag(tmp)=2
num1=floor(nloc/ncommun)
for (i in 1:300){
seq1=(ncommun*(i-1)+1):(ncommun*i)
xmat[seq1,]=tmp
}
image(xmat)
xmat=cbind(1,xmat)
#parameters
b0=log(runif(ncommun,min=5,max=8))
betas.true=betas=rbind(b0,diag(1,ncommun))
#get means
media.true=media=exp(xmat%*%betas); range(media)
head(media)
#generate N_lk
par(mfrow=c(1,1),mar=rep(4,4))
nlk=matrix(NA,nloc,ncommun)
NBN=10 #when this is large, we get into areas with relatively flat loglikel, giving trouble to the slice sampler
for (i in 1:ncommun){
nlk[,i]=rnbinom(nloc,mu=media[,i],size=NBN)
}
nlk.true=nlk; boxplot(nlk)
soma=apply(nlk,1,sum); sum(soma==0)
theta.true=theta=nlk/soma; apply(theta,1,sum);
boxplot(theta); apply(theta,2,range); apply(theta>0.95,2,mean)
nl=apply(nlk,1,sum)
hist(nl)
sum(nl)
plot(media,nlk)
#generate phi:
#- assume that each species is strongly present in a single group
#- Avoid very rare species (species that are almost never present)
tmp=matrix(0,ncommun,nspp)
base=nspp/ncommun
margin1=floor(base*0.2)
seq1=c(seq(from=1,to=nspp,by=base),nspp-margin1)
for (i in 1:(length(seq1)-1)){ #add some zeroes
seq2=seq1[i]:(seq1[i+1]+margin1)
tmp[i,seq2]=1
}
phi=tmp/matrix(rowSums(tmp),ncommun,nspp) #re-scale to make sure it sums to 1
phi.true=phi
# round(phi[,1:20],2)
# table(round(phi,2))
unique(rowSums(phi))
phi.true=phi
image(phi)
#generate actual observations y
array.lsk=array(0,dim=c(nloc,nspp,ncommun))
for (i in 1:nloc){
for (k in 1:ncommun){
array.lsk[i,,k]=rmultinom(1,size=nlk[i,k],prob=phi[k,])
}
}
array.lsk.true=array.lsk
y=apply(array.lsk,c(1,2),sum)
nks=t(apply(array.lsk,c(2,3),sum))
image(y)
phi.estim=nks/rowSums(nks)
rango=range(c(phi,phi.estim))
plot(phi,phi.estim,ylim=rango,xlim=rango)
lines(rango,rango,col='red')
#checking if it makes sense
plot(apply(array.lsk,c(1,3),sum),nlk)
lines(c(0,1000),c(0,1000))
#look at stuff to make sure it makes sense
phi.estim=nks/matrix(rowSums(nks),ncommun,nspp)
plot(phi.true,phi.estim)
nks.true=nks
tmp=res$phi[length(res$llk),]
phi=matrix(tmp,ncomm.init,nspp)
phi1=phi[1:ncomm,]
ordem=numeric()
for (i in 1:ncomm){
tmp=rep(0,ncomm)
for (j in 1:ncomm){
tmp[j]=cor(phi.true[i,],phi1[j,])
}
ind=which(tmp==max(tmp))
ordem=c(ordem,ind)
}
rango=range(c(phi.true,phi1))
plot(phi.true,phi1[ordem,],xlim=rango,ylim=rango)
lines(rango,rango,col='red')
array.lsk.init=res$array.lsk
nlk=apply(array.lsk.init,c(1,3),sum)
theta=nlk/apply(nlk,1,sum)
rango=range(c(theta.true,theta))
plot(theta.true,theta[,ordem],xlim=rango,ylim=rango)
lines(rango,rango,col='red')
rm(list=ls(all=TRUE))
library(MCMCpack)
library('Rcpp')
set.seed(10)
#get data
setwd('U:\\GIT_models\\git_LDA_MS')
dat=read.csv('fake data.csv',as.is=T)
xmat=data.matrix(read.csv('fake data xmat.csv',as.is=T))
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
#get array.lsk
tmp=read.csv('array lsk.csv',as.is=T)
ncomm=length(tmp$V1)/(nspp*nloc); ncomm
array.lsk.init=array(tmp$V1,dim=c(nloc,nspp,ncomm))
#basic settings
ngibbs=1000
nburn=ngibbs/2
#priors
phi.prior=0.01
var.betas=c(10,rep(10,ncol(xmat)-1))
gamma=0.1
#----------------------------------------------------------
#LDA with covariates
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('LDA cov main function.R')
source('LDA cov aux functions.R')
sourceCpp('LDA_cov_aux1_cpp.cpp')
sourceCpp('slice_betas.cpp')
sourceCpp('slice_NBN.cpp')
res=gibbs.LDA.cov(ncomm=ncomm,ngibbs=ngibbs,nburn=nburn,y=y,xmat=xmat,
phi.prior=phi.prior,array.lsk.init=array.lsk.init,
var.betas=var.betas)
plot(res$llk,type='l')
plot(res$fmodel,type='l')
plot(res$llk[1:ngibbs],type='l')
nburn=500
plot(res$llk[nburn:ngibbs],type='l')
nburn=900
plot(res$llk[nburn:ngibbs],type='l')
effectiveSize(mcmc(res$betas[nburn:ngibbs,]))
plot(res$betas[nburn:ngibbs,1],type='l')
plot(res$llk[nburn:ngibbs],type='l')
effectiveSize(mcmc(res$betas[nburn:ngibbs,]))
plot(res$betas[nburn:ngibbs,1],type='l')
plot(res$NBN,type='l')
compare1=function(estim,true){
rango=range(c(true,estim))
plot(true,estim,ylim=rango,xlim=rango)
lines(rango,rango,col='red',lwd=2)
}
k=res$betas[ngibbs,]
nparam=ncol(xmat)
k1=matrix(k,nparam,ncomm); round(k1,2)
ordem=rep(NA,ncomm)
for (i in 2:nparam){
ordem[i-1]=which(k1[i,]==max(k1[i,]))
}
round(k1[,ordem],2)
#look at nlk
par(mfrow=c(1,1))
tmp=matrix(res$nlk[ngibbs,],nloc,ncomm);
boxplot(tmp)
compare1(estim=jitter(tmp[,ordem]),true=jitter(nlk.true))
library(MCMCpack)
set.seed(13)
nloc=3000
nspp=150
ncommun=5
#design matrix
xmat=matrix(runif(nloc*ncommun,min=-1,max=3),nloc,ncommun)
#pure sites
tmp=matrix(-3,ncommun,ncommun)
diag(tmp)=2
num1=floor(nloc/ncommun)
for (i in 1:300){
seq1=(ncommun*(i-1)+1):(ncommun*i)
xmat[seq1,]=tmp
}
image(xmat)
xmat=cbind(1,xmat)
#parameters
b0=log(runif(ncommun,min=5,max=8))
betas.true=betas=rbind(b0,diag(1,ncommun))
#get means
media.true=media=exp(xmat%*%betas); range(media)
head(media)
#generate N_lk
par(mfrow=c(1,1),mar=rep(4,4))
nlk=matrix(NA,nloc,ncommun)
NBN=10 #when this is large, we get into areas with relatively flat loglikel, giving trouble to the slice sampler
for (i in 1:ncommun){
nlk[,i]=rnbinom(nloc,mu=media[,i],size=NBN)
}
nlk.true=nlk; boxplot(nlk)
soma=apply(nlk,1,sum); sum(soma==0)
theta.true=theta=nlk/soma; apply(theta,1,sum);
boxplot(theta); apply(theta,2,range); apply(theta>0.95,2,mean)
nl=apply(nlk,1,sum)
hist(nl)
sum(nl)
plot(media,nlk)
#generate phi:
#- assume that each species is strongly present in a single group
#- Avoid very rare species (species that are almost never present)
tmp=matrix(0,ncommun,nspp)
base=nspp/ncommun
margin1=floor(base*0.2)
seq1=c(seq(from=1,to=nspp,by=base),nspp-margin1)
for (i in 1:(length(seq1)-1)){ #add some zeroes
seq2=seq1[i]:(seq1[i+1]+margin1)
tmp[i,seq2]=1
}
phi=tmp/matrix(rowSums(tmp),ncommun,nspp) #re-scale to make sure it sums to 1
phi.true=phi
# round(phi[,1:20],2)
# table(round(phi,2))
unique(rowSums(phi))
phi.true=phi
image(phi)
#generate actual observations y
array.lsk=array(0,dim=c(nloc,nspp,ncommun))
for (i in 1:nloc){
for (k in 1:ncommun){
array.lsk[i,,k]=rmultinom(1,size=nlk[i,k],prob=phi[k,])
}
}
array.lsk.true=array.lsk
y=apply(array.lsk,c(1,2),sum)
nks=t(apply(array.lsk,c(2,3),sum))
image(y)
phi.estim=nks/rowSums(nks)
rango=range(c(phi,phi.estim))
plot(phi,phi.estim,ylim=rango,xlim=rango)
lines(rango,rango,col='red')
#checking if it makes sense
plot(apply(array.lsk,c(1,3),sum),nlk)
lines(c(0,1000),c(0,1000))
#look at stuff to make sure it makes sense
phi.estim=nks/matrix(rowSums(nks),ncommun,nspp)
plot(phi.true,phi.estim)
nks.true=nks
#look at nlk
par(mfrow=c(1,1))
tmp=matrix(res$nlk[ngibbs,],nloc,ncomm);
boxplot(tmp)
compare1(estim=jitter(tmp[,ordem]),true=jitter(nlk.true))
#look at betas
k=matrix(res$betas[ngibbs,],nparam,ncomm)
compare1(estim=k[,ordem],true=betas.true)
#look at phi
tmp=matrix(res$phi[ngibbs,],ncomm,nspp)
tmp1=tmp[ordem,]
compare1(estim=tmp1,true=phi.true)
