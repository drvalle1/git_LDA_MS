nburn=ngibbs/2
#useful stuff
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
nparam=ncol(dmat)
hi=0.999999
lo=0.000001
td=t(dmat)
dtd=td%*%dmat
invT=diag(1/100,nparam)
pot.sig2=seq(from=0.1,to=3.7,by=0.1)
#initial values
theta=matrix(1/ncomm,nloc,ncomm)
phi=matrix(1/nspp,ncomm,nspp)
psi=matrix(0,nloc,ncomm-1)
betas=matrix(0,nparam,ncomm-1)
sig2=rep(1,ncomm-1)
#to store outcomes from gibbs sampler
theta.out=matrix(NA,ngibbs,ncomm*nloc)
phi.out=matrix(NA,ngibbs,ncomm*nspp)
psi.out=matrix(NA,ngibbs,nloc*(ncomm-1))
beta.out=matrix(NA,ngibbs,nparam*(ncomm-1))
sig2.out=matrix(NA,ngibbs,ncomm-1)
llk=rep(NA,ngibbs)
#run gibbs sampler
options(warn=2)
change1=50
for (i in 1:ngibbs){
print(c(i,range(psi)))
#sample z
tmp=samplez(theta=theta, phi=phi, y=y, ncommun=ncomm, nloc=nloc, nspp=nspp)
nlk=tmp$nlk
nks=tmp$nks
#get w
tmp=get.w(nlk=nlk,psi=psi,ncomm=ncomm,nloc=nloc)
soma=tmp$soma
#get psi
tmp=get.psi(soma=soma,nlk=nlk,sig2=sig2,mu=mu,ncomm=ncomm,theta=theta,nks=nks,change1=change1,
nburn=nburn,i=i,dmat=dmat,betas=betas)
psi=tmp$psi
nlk=tmp$nlk
nks=tmp$nks
soma=tmp$soma
betas=tmp$betas
sig2=tmp$sig2
v=pnorm(psi) #calculate implied theta
theta=convertVtoTheta(vmat=cbind(v,1),prod=rep(1,nloc))
#sample phi
phi=rdirichlet1(alpha=nks+phi.prior,ncomm=ncomm,nspp=nspp)
#sample betas
betas=get.betas(psi=psi,nloc=nloc,mu=mu,sig2=sig2,
ncomm=ncomm,td=td,dtd=dtd,invT=invT,nparam=nparam)
#sample sig2
# sig2=get.sig2(psi=psi,nloc=nloc,mu=mu,ncomm=ncomm,dmat=dmat,betas=betas,pot.sig2=pot.sig2)
sig2=c(1,2,1)
#calculate loglikelihood
prob=theta%*%phi
prob[prob>hi]=hi; prob[prob<lo]=lo
#store results
llk[i]=sum(y*log(prob))
theta.out[i,]=theta
phi.out[i,]=phi
psi.out[i,]=psi
beta.out[i,]=betas
sig2.out[i,]=sig2
}
rm(list=ls(all=TRUE))
library('Rcpp')
library('mvtnorm')
set.seed(4)
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('gibbs functions.R')
source('gibbs sampler main function.R')
sourceCpp('aux1.cpp')
#get data
tmp=read.csv('fake data4.csv',as.is=T)
ind=which(colnames(tmp)=='X')
dat=tmp[,-ind]
nloc=nrow(dat)
dmat=read.csv('fake data4 dmat.csv',as.is=T)
dmat=data.matrix(dmat)
#basic settings
mu=3
ncomm=4
ngibbs=1000
phi.prior=0.1
nburn=ngibbs/2
#useful stuff
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
nparam=ncol(dmat)
hi=0.999999
lo=0.000001
td=t(dmat)
dtd=td%*%dmat
invT=diag(1/100,nparam)
pot.sig2=seq(from=0.1,to=3.7,by=0.1)
#initial values
theta=matrix(1/ncomm,nloc,ncomm)
phi=matrix(1/nspp,ncomm,nspp)
psi=matrix(0,nloc,ncomm-1)
betas=matrix(0,nparam,ncomm-1)
sig2=rep(1,ncomm-1)
#to store outcomes from gibbs sampler
theta.out=matrix(NA,ngibbs,ncomm*nloc)
phi.out=matrix(NA,ngibbs,ncomm*nspp)
psi.out=matrix(NA,ngibbs,nloc*(ncomm-1))
beta.out=matrix(NA,ngibbs,nparam*(ncomm-1))
sig2.out=matrix(NA,ngibbs,ncomm-1)
llk=rep(NA,ngibbs)
#run gibbs sampler
options(warn=2)
change1=50
for (i in 1:ngibbs){
print(c(i,range(psi)))
#sample z
tmp=samplez(theta=theta, phi=phi, y=y, ncommun=ncomm, nloc=nloc, nspp=nspp)
nlk=tmp$nlk
nks=tmp$nks
#get w
tmp=get.w(nlk=nlk,psi=psi,ncomm=ncomm,nloc=nloc)
soma=tmp$soma
#get psi
tmp=get.psi(soma=soma,nlk=nlk,sig2=sig2,mu=mu,ncomm=ncomm,theta=theta,nks=nks,change1=change1,
nburn=nburn,i=i,dmat=dmat,betas=betas)
psi=tmp$psi
nlk=tmp$nlk
nks=tmp$nks
soma=tmp$soma
betas=tmp$betas
sig2=tmp$sig2
v=pnorm(psi) #calculate implied theta
theta=convertVtoTheta(vmat=cbind(v,1),prod=rep(1,nloc))
#sample phi
phi=rdirichlet1(alpha=nks+phi.prior,ncomm=ncomm,nspp=nspp)
#sample betas
betas=get.betas(psi=psi,nloc=nloc,mu=mu,sig2=sig2,
ncomm=ncomm,td=td,dtd=dtd,invT=invT,nparam=nparam)
#sample sig2
# sig2=get.sig2(psi=psi,nloc=nloc,mu=mu,ncomm=ncomm,dmat=dmat,betas=betas,pot.sig2=pot.sig2)
sig2=c(1,2,1)
#calculate loglikelihood
prob=theta%*%phi
prob[prob>hi]=hi; prob[prob<lo]=lo
#store results
llk[i]=sum(y*log(prob))
theta.out[i,]=theta
phi.out[i,]=phi
psi.out[i,]=psi
beta.out[i,]=betas
sig2.out[i,]=sig2
}
rm(list=ls(all=TRUE))
library('Rcpp')
library('mvtnorm')
set.seed(4)
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('gibbs functions.R')
source('gibbs sampler main function.R')
sourceCpp('aux1.cpp')
#get data
tmp=read.csv('fake data4.csv',as.is=T)
ind=which(colnames(tmp)=='X')
dat=tmp[,-ind]
nloc=nrow(dat)
dmat=read.csv('fake data4 dmat.csv',as.is=T)
dmat=data.matrix(dmat)
#basic settings
mu=3
ncomm=4
ngibbs=1000
phi.prior=0.1
nburn=ngibbs/2
ngibbs=49
#useful stuff
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
nparam=ncol(dmat)
hi=0.999999
lo=0.000001
td=t(dmat)
dtd=td%*%dmat
invT=diag(1/100,nparam)
pot.sig2=seq(from=0.1,to=3.7,by=0.1)
#initial values
theta=matrix(1/ncomm,nloc,ncomm)
phi=matrix(1/nspp,ncomm,nspp)
psi=matrix(0,nloc,ncomm-1)
betas=matrix(0,nparam,ncomm-1)
sig2=rep(1,ncomm-1)
#to store outcomes from gibbs sampler
theta.out=matrix(NA,ngibbs,ncomm*nloc)
phi.out=matrix(NA,ngibbs,ncomm*nspp)
psi.out=matrix(NA,ngibbs,nloc*(ncomm-1))
beta.out=matrix(NA,ngibbs,nparam*(ncomm-1))
sig2.out=matrix(NA,ngibbs,ncomm-1)
llk=rep(NA,ngibbs)
#run gibbs sampler
options(warn=2)
change1=50
for (i in 1:ngibbs){
print(c(i,range(psi)))
#sample z
tmp=samplez(theta=theta, phi=phi, y=y, ncommun=ncomm, nloc=nloc, nspp=nspp)
nlk=tmp$nlk
nks=tmp$nks
#get w
tmp=get.w(nlk=nlk,psi=psi,ncomm=ncomm,nloc=nloc)
soma=tmp$soma
#get psi
tmp=get.psi(soma=soma,nlk=nlk,sig2=sig2,mu=mu,ncomm=ncomm,theta=theta,nks=nks,change1=change1,
nburn=nburn,i=i,dmat=dmat,betas=betas)
psi=tmp$psi
nlk=tmp$nlk
nks=tmp$nks
soma=tmp$soma
betas=tmp$betas
sig2=tmp$sig2
v=pnorm(psi) #calculate implied theta
theta=convertVtoTheta(vmat=cbind(v,1),prod=rep(1,nloc))
#sample phi
phi=rdirichlet1(alpha=nks+phi.prior,ncomm=ncomm,nspp=nspp)
#sample betas
betas=get.betas(psi=psi,nloc=nloc,mu=mu,sig2=sig2,
ncomm=ncomm,td=td,dtd=dtd,invT=invT,nparam=nparam)
#sample sig2
# sig2=get.sig2(psi=psi,nloc=nloc,mu=mu,ncomm=ncomm,dmat=dmat,betas=betas,pot.sig2=pot.sig2)
sig2=c(1,2,1)
#calculate loglikelihood
prob=theta%*%phi
prob[prob>hi]=hi; prob[prob<lo]=lo
#store results
llk[i]=sum(y*log(prob))
theta.out[i,]=theta
phi.out[i,]=phi
psi.out[i,]=psi
beta.out[i,]=betas
sig2.out[i,]=sig2
}
i=50
tmp=samplez(theta=theta, phi=phi, y=y, ncommun=ncomm, nloc=nloc, nspp=nspp)
nlk=tmp$nlk
nks=tmp$nks
#get w
tmp=get.w(nlk=nlk,psi=psi,ncomm=ncomm,nloc=nloc)
soma=tmp$soma
print(c(i,range(psi)))
i%%change1 == 0 & i<nburn
med=colMeans(theta)
boxplot(theta)
order(med,decreasing=T)
rm(list=ls(all=TRUE))
library('Rcpp')
library('mvtnorm')
set.seed(4)
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('gibbs functions.R')
source('gibbs sampler main function.R')
sourceCpp('aux1.cpp')
#get data
tmp=read.csv('fake data4.csv',as.is=T)
ind=which(colnames(tmp)=='X')
dat=tmp[,-ind]
nloc=nrow(dat)
dmat=read.csv('fake data4 dmat.csv',as.is=T)
dmat=data.matrix(dmat)
#basic settings
mu=3
ncomm=4
ngibbs=1000
phi.prior=0.1
nburn=ngibbs/2
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
nparam=ncol(dmat)
hi=0.999999
lo=0.000001
td=t(dmat)
dtd=td%*%dmat
invT=diag(1/100,nparam)
pot.sig2=seq(from=0.1,to=3.7,by=0.1)
#initial values
theta=matrix(1/ncomm,nloc,ncomm)
phi=matrix(1/nspp,ncomm,nspp)
psi=matrix(0,nloc,ncomm-1)
betas=matrix(0,nparam,ncomm-1)
sig2=rep(1,ncomm-1)
#to store outcomes from gibbs sampler
theta.out=matrix(NA,ngibbs,ncomm*nloc)
phi.out=matrix(NA,ngibbs,ncomm*nspp)
psi.out=matrix(NA,ngibbs,nloc*(ncomm-1))
beta.out=matrix(NA,ngibbs,nparam*(ncomm-1))
sig2.out=matrix(NA,ngibbs,ncomm-1)
llk=rep(NA,ngibbs)
#run gibbs sampler
options(warn=2)
change1=50
for (i in 1:ngibbs){
print(c(i,range(psi)))
#sample z
tmp=samplez(theta=theta, phi=phi, y=y, ncommun=ncomm, nloc=nloc, nspp=nspp)
nlk=tmp$nlk
nks=tmp$nks
#get w
tmp=get.w(nlk=nlk,psi=psi,ncomm=ncomm,nloc=nloc)
soma=tmp$soma
#get psi
tmp=get.psi(soma=soma,nlk=nlk,sig2=sig2,mu=mu,ncomm=ncomm,theta=theta,nks=nks,change1=change1,
nburn=nburn,i=i,dmat=dmat,betas=betas)
psi=tmp$psi
nlk=tmp$nlk
nks=tmp$nks
soma=tmp$soma
betas=tmp$betas
sig2=tmp$sig2
v=pnorm(psi) #calculate implied theta
theta=convertVtoTheta(vmat=cbind(v,1),prod=rep(1,nloc))
#sample phi
phi=rdirichlet1(alpha=nks+phi.prior,ncomm=ncomm,nspp=nspp)
#sample betas
betas=get.betas(psi=psi,nloc=nloc,mu=mu,sig2=sig2,
ncomm=ncomm,td=td,dtd=dtd,invT=invT,nparam=nparam)
#sample sig2
# sig2=get.sig2(psi=psi,nloc=nloc,mu=mu,ncomm=ncomm,dmat=dmat,betas=betas,pot.sig2=pot.sig2)
sig2=c(1,2,1)
#calculate loglikelihood
prob=theta%*%phi
prob[prob>hi]=hi; prob[prob<lo]=lo
#store results
llk[i]=sum(y*log(prob))
theta.out[i,]=theta
phi.out[i,]=phi
psi.out[i,]=psi
beta.out[i,]=betas
sig2.out[i,]=sig2
}
rm(list=ls(all=TRUE))
library('Rcpp')
library('mvtnorm')
set.seed(4)
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('gibbs functions.R')
source('gibbs sampler main function.R')
sourceCpp('aux1.cpp')
#get data
tmp=read.csv('fake data4.csv',as.is=T)
ind=which(colnames(tmp)=='X')
dat=tmp[,-ind]
nloc=nrow(dat)
dmat=read.csv('fake data4 dmat.csv',as.is=T)
dmat=data.matrix(dmat)
#basic settings
mu=3
ncomm=4
ngibbs=1000
phi.prior=0.1
nburn=ngibbs/2
ngibbs=99
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
nparam=ncol(dmat)
hi=0.999999
lo=0.000001
td=t(dmat)
dtd=td%*%dmat
invT=diag(1/100,nparam)
pot.sig2=seq(from=0.1,to=3.7,by=0.1)
#initial values
theta=matrix(1/ncomm,nloc,ncomm)
phi=matrix(1/nspp,ncomm,nspp)
psi=matrix(0,nloc,ncomm-1)
betas=matrix(0,nparam,ncomm-1)
sig2=rep(1,ncomm-1)
#to store outcomes from gibbs sampler
theta.out=matrix(NA,ngibbs,ncomm*nloc)
phi.out=matrix(NA,ngibbs,ncomm*nspp)
psi.out=matrix(NA,ngibbs,nloc*(ncomm-1))
beta.out=matrix(NA,ngibbs,nparam*(ncomm-1))
sig2.out=matrix(NA,ngibbs,ncomm-1)
llk=rep(NA,ngibbs)
#run gibbs sampler
options(warn=2)
change1=50
for (i in 1:ngibbs){
print(c(i,range(psi)))
#sample z
tmp=samplez(theta=theta, phi=phi, y=y, ncommun=ncomm, nloc=nloc, nspp=nspp)
nlk=tmp$nlk
nks=tmp$nks
#get w
tmp=get.w(nlk=nlk,psi=psi,ncomm=ncomm,nloc=nloc)
soma=tmp$soma
#get psi
tmp=get.psi(soma=soma,nlk=nlk,sig2=sig2,mu=mu,ncomm=ncomm,theta=theta,nks=nks,change1=change1,
nburn=nburn,i=i,dmat=dmat,betas=betas)
psi=tmp$psi
nlk=tmp$nlk
nks=tmp$nks
soma=tmp$soma
betas=tmp$betas
sig2=tmp$sig2
v=pnorm(psi) #calculate implied theta
theta=convertVtoTheta(vmat=cbind(v,1),prod=rep(1,nloc))
#sample phi
phi=rdirichlet1(alpha=nks+phi.prior,ncomm=ncomm,nspp=nspp)
#sample betas
betas=get.betas(psi=psi,nloc=nloc,mu=mu,sig2=sig2,
ncomm=ncomm,td=td,dtd=dtd,invT=invT,nparam=nparam)
#sample sig2
# sig2=get.sig2(psi=psi,nloc=nloc,mu=mu,ncomm=ncomm,dmat=dmat,betas=betas,pot.sig2=pot.sig2)
sig2=c(1,2,1)
#calculate loglikelihood
prob=theta%*%phi
prob[prob>hi]=hi; prob[prob<lo]=lo
#store results
llk[i]=sum(y*log(prob))
theta.out[i,]=theta
phi.out[i,]=phi
psi.out[i,]=psi
beta.out[i,]=betas
sig2.out[i,]=sig2
}
i=100
print(c(i,range(psi)))
tmp=samplez(theta=theta, phi=phi, y=y, ncommun=ncomm, nloc=nloc, nspp=nspp)
nlk=tmp$nlk
nks=tmp$nks
#get w
tmp=get.w(nlk=nlk,psi=psi,ncomm=ncomm,nloc=nloc)
soma=tmp$soma
boxplot(soma)
i%%change1 == 0 & i<nburn
med=colMeans(theta)
boxplot(theta)
order(med,decreasing=T)
ind=order(med,decreasing=T)
ind1=ind[ind!=ncomm]
nlk=cbind(nlk[,ind1],nlk[,ncomm])
nks=rbind(nks[ind1,],nks[ncomm,])
soma=soma[,ind1]
sig2=sig2[ind1]
betas=betas[,ind1]
mu
medias=mu+dmat%*%betas
nge=ngreater(nlk=nlk,nloc=nloc,ncommun=ncomm) #greater or equal
sig2.mat=matrix(sig2,nloc,ncomm-1,byrow=T)
prec=nge[,-ncomm]+(1/sig2.mat)
var1=1/prec
pmedia=soma+(medias/sig2.mat)
tmp=rnorm(nloc*(ncomm-1),mean=var1*pmedia,sd=sqrt(var1))
psi=matrix(tmp,nloc,ncomm-1)
range(psi)
apply(psi,2,range)
apply(var1,2,range)
apply(medias,2,range)
apply(nge,2,range)
apply(soma,2,range)
apply(var1*pmedia,2,mean)
apply(var1*pmedia,2,range)
z=var1*pmedia
z=(var1*pmedia)[,2]
ind=which(z < -1000)
ind
var1[1055,2]
pmedia[1055,2]
soma[1055,2]
boxplot(soma)
(medias/sig2.mat)[1055,2]
var1[1055,2]
var1[,2]
head(sig2.mat)
sig2
(var1*pmedia)[1055,2]
var1[1055,2]
z=nge[,-ncomm]
z[1055,2]
plot(z[,2])
plot(z[,3])
plot(z[,1])
rm(list=ls(all=TRUE))
library('Rcpp')
library('mvtnorm')
set.seed(4)
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('gibbs functions.R')
source('gibbs sampler main function.R')
sourceCpp('aux1.cpp')
#get data
tmp=read.csv('fake data4.csv',as.is=T)
ind=which(colnames(tmp)=='X')
dat=tmp[,-ind]
nloc=nrow(dat)
dmat=read.csv('fake data4 dmat.csv',as.is=T)
dmat=data.matrix(dmat)
#basic settings
mu=3
ncomm=4
ngibbs=1000
phi.prior=0.1
nburn=ngibbs/2
#fit model
res=lda.abundance.regression(dat=dat,ncomm=ncomm,phi.prior=phi.prior,ngibbs=ngibbs,mu=mu,nburn=nburn,dmat=dmat)
