theta.old=media.old/soma.media.old
theta.new=media.new/soma.media.new
prob.old=theta.old%*%phi
prob.new=theta.new%*%phi
p1.old=sum(y*log(prob.old))
p1.new=sum(y*log(prob.new))
p2.old=sum(dpois(ntot,soma.media.old,log=T))
p2.new=sum(dpois(ntot,soma.media.new,log=T))
pold=p1.old+p2.old+prior.old[i,j]
pnew=p1.new+p2.new+prior.new[i,j]
pthresh=exp(pnew-pold)
if (runif(1)<pthresh){
betas.old[i,j]=betas.new[i,j]
media.old[,j]=media.new[,j]
}
}
}
list(betas=betas.old,accept=betas.old!=betas.orig)
}
#---------------------------------
sample.betas.arma=function(y,xmat,betas,ncomm,nparam,jump,var.betas,phi,ntot){
betas.orig=betas.old=betas.prop=betas
betas.prop[]=rnorm(nparam*ncomm,mean=betas.old,sd=jump)
var.betas1=matrix(var.betas,nparam,ncomm)
prior.old=dnorm(betas.orig,mean=0,sd=sqrt(var.betas1),log=T)
prior.new=dnorm(betas.prop,mean=0,sd=sqrt(var.betas1),log=T)
runif1=matrix(runif(nparam*ncomm),nparam,ncomm)
betas=sampleBetas(y=y,xmat=xmat,betas_prop=betas.prop,
prior_old=prior.old, prior_new=prior.new, runif1=runif1,
betas=betas, phi=phi,ntot=ntot,
ncomm=ncomm,nparam=nparam, nloc=nloc, nspp=nspp)
list(betas=betas,accept=betas!=betas.orig)
}
microbenchmark(
tmp=sample.betas.arma(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot),
tmp=sample.betas.R(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot)
)
library(microbenchmark)
microbenchmark(
tmp=sample.betas.arma(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot),
tmp=sample.betas.R(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot)
)
rm(list=ls(all=TRUE))
library(MCMCpack)
library('Rcpp')
library('RcppArmadillo')
set.seed(10)
#get data
setwd('U:\\GIT_models\\git_LDA_MS')
dat=read.csv('fake data.csv',as.is=T)
xmat=data.matrix(read.csv('fake data xmat.csv',as.is=T))
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
#get array.lsk
tmp=read.csv('array lsk.csv',as.is=T)
ncomm=9 #this was estimated based on a previous step
array.lsk.init=array(tmp$V1,dim=c(nloc,nspp,ncomm))
#basic settings
ngibbs=1000
nburn=ngibbs/2
#priors
phi.prior=0.01
var.betas=c(10,rep(1,ncol(xmat)-1))
gamma=0.1
#----------------------------------------------------------
#LDA with covariates
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('LDA cov main function.R')
source('LDA cov aux functions.R')
sourceCpp('LDA_cov_aux1_cpp.cpp')
nparam=ncol(xmat)
nloc=nrow(y)
nspp=ncol(y)
ntot=apply(y,1,sum)
#initial values
array.lsk=array.lsk.init
nlk=apply(array.lsk,c(1,3),sum)
betas=matrix(0,nparam,ncomm)
options(warn=-1) #sometimes I get "glm.fit: fitted rates numerically 0 occurred" here
for (i in 1:ncomm){
dat.tmp=cbind(nlk[,i],xmat[,-1])
colnames(dat.tmp)[1]='y'
dat.tmp1=as.data.frame(dat.tmp)
res=glm(y~.,data=dat.tmp1,family='poisson')
betas[,i]=res$coef
}
options(warn=2)
nks=t(apply(array.lsk,2:3,sum))
phi=nks/apply(nks,1,sum); apply(phi,1,sum)
#to store outcomes from gibbs sampler
phi.out=matrix(NA,ngibbs,nspp*ncomm)
nlk.out=matrix(NA,ngibbs,nloc*ncomm)
llk.out=rep(NA,ngibbs)
fmodel.out=matrix(NA,ngibbs,1)
betas.out=matrix(NA,ngibbs,nparam*ncomm)
#useful stuff for MH algorithm
accept1=list(betas=matrix(0,nparam,ncomm))
jump1=list(betas=matrix(0.1,nparam,ncomm))
accept.output=50
nadapt=ngibbs/2
#run gibbs sampler
options(warn=2)
microbenchmark(
tmp=sample.betas.arma(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot),
tmp=sample.betas.R(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot)
)
sample.betas.R=function(y,xmat,betas,ncomm,nparam,jump,var.betas,phi,ntot){
betas.orig=betas.old=betas.prop=betas
betas.prop[]=rnorm(nparam*ncomm,mean=betas.old,sd=jump)
var.betas1=matrix(var.betas,nparam,ncomm)
prior.old=dnorm(betas.orig,mean=0,sd=sqrt(var.betas1),log=T)
prior.new=dnorm(betas.prop,mean=0,sd=sqrt(var.betas1),log=T)
media.old=media.new=exp(xmat%*%betas.old)
for (i in 1:nparam){
for (j in 1:ncomm){
betas.new=betas.old
betas.new[i,j]=betas.prop[i,j]
media.new[,j]=exp(xmat%*%betas.new[,j])
soma.media.old=rowSums(media.old)
soma.media.new=rowSums(media.new)
theta.old=media.old/soma.media.old
theta.new=media.new/soma.media.new
prob.old=theta.old%*%phi
prob.new=theta.new%*%phi
p1.old=sum(y*log(prob.old))
p1.new=sum(y*log(prob.new))
p2.old=sum(dpois(ntot,soma.media.old,log=T))
p2.new=sum(dpois(ntot,soma.media.new,log=T))
pold=p1.old+p2.old+prior.old[i,j]
pnew=p1.new+p2.new+prior.new[i,j]
pthresh=exp(pnew-pold)
if (runif(1)<pthresh){
betas.old[i,j]=betas.new[i,j]
media.old[,j]=media.new[,j]
}
}
}
list(betas=betas.old,accept=betas.old!=betas.orig)
}
#---------------------------------
sample.betas.arma=function(y,xmat,betas,ncomm,nparam,jump,var.betas,phi,ntot){
betas.orig=betas.old=betas.prop=betas
betas.prop[]=rnorm(nparam*ncomm,mean=betas.old,sd=jump)
var.betas1=matrix(var.betas,nparam,ncomm)
prior.old=dnorm(betas.orig,mean=0,sd=sqrt(var.betas1),log=T)
prior.new=dnorm(betas.prop,mean=0,sd=sqrt(var.betas1),log=T)
runif1=matrix(runif(nparam*ncomm),nparam,ncomm)
betas=sampleBetas(y=y,xmat=xmat,betas_prop=betas.prop,
prior_old=prior.old, prior_new=prior.new, runif1=runif1,
betas=betas, phi=phi,ntot=ntot,
ncomm=ncomm,nparam=nparam, nloc=nloc, nspp=nspp)
list(betas=betas,accept=betas!=betas.orig)
}
microbenchmark(
tmp=sample.betas.arma(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot),
tmp=sample.betas.R(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot)
)
?microbenchmark
microbenchmark(
tmp=sample.betas.arma(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot),times=10
)
microbenchmark(
sample.betas.R(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot),times=10
)
microbenchmark(
sample.betas.arma(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot),
sample.betas.R(y=y,xmat=xmat,betas=betas,
ncomm=ncomm,nparam=nparam,jump=jump1$betas,
var.betas=var.betas,phi=phi,ntot=ntot),
times=10
)
1.730569/2.1363
rm(list=ls(all=TRUE))
library(MCMCpack)
set.seed(30)
nloc=3000
nspp=100
ncommun=4
#design matrix
xmat=matrix(runif(nloc*ncommun,min=-3,max=3),nloc,ncommun)
#pure sites
tmp=matrix(-3,ncommun,ncommun)
diag(tmp)=3
num1=floor(nloc/ncommun)
for (i in 1:200){
seq1=(ncommun*(i-1)+1):(ncommun*i)
xmat[seq1,]=tmp
}
image(xmat)
xmat=cbind(1,xmat)
#parameters
b0=log(runif(ncommun,min=4,max=7))
betas.true=betas=rbind(b0,diag(1,ncommun))
#get means
media.true=media=exp(xmat%*%betas); range(media)
head(media)
#generate N_lk
par(mfrow=c(1,1),mar=rep(4,4))
nlk=matrix(NA,nloc,ncommun)
for (i in 1:ncommun){
nlk[,i]=rpois(nloc,media[,i])
}
nlk.true=nlk; boxplot(nlk)
z=nlk/apply(nlk,1,sum); apply(z,1,sum); boxplot(z); apply(z,2,range); apply(z>0.9,2,mean)
nl=apply(nlk,1,sum)
hist(nl)
sum(nl)
plot(media,nlk)
#generate phi (assuming that each species is strongly present in a single group)
phi=matrix(0.01,ncommun,nspp)
num=floor(nspp/ncommun)
for (i in 1:nspp){
n=rbinom(1,size=1,prob=0.1)+1
ind=sample(1:ncommun,size=n)
phi[ind,i]=1
}
phi.true=phi=phi/matrix(apply(phi,1,sum),ncommun,nspp)
apply(phi,1,sum)
image(phi[,1:20])
#per species
par(mfrow=c(4,2),mar=rep(1,4))
for (i in 1:(ncommun*2)) plot(phi[,i]/sum(phi[,i]),type='h',ylim=c(0,1))
par(mfrow=c(4,2),mar=rep(1,4))
for (i in 1:ncommun) plot(phi[i,],type='h')
# for (i in 1:nspp){ #add some zeroes
#   ind=sample(1:ncommun,size=1)
#   tmp[ind,i]=runif(1,min=0.5,max=1)
# }
# phi=tmp/matrix(rowSums(tmp),ncommun,nspp) #re-scale to make sure it sums to 1
# round(phi[,1:20],2)
# table(round(phi,2))
unique(rowSums(phi))
phi.true=phi
image(phi)
#generate actual observations y
array.lsk=array(0,dim=c(nloc,nspp,ncommun))
for (i in 1:nloc){
for (k in 1:ncommun){
array.lsk[i,,k]=rmultinom(1,size=nlk[i,k],prob=phi[k,])
}
}
array.lsk.true=array.lsk
y=apply(array.lsk,c(1,2),sum)
nks=t(apply(array.lsk,c(2,3),sum))
image(y)
plot(phi,nks)
#checking if it makes sense
plot(apply(array.lsk,c(1,3),sum),nlk)
lines(c(0,1000),c(0,1000))
#look at stuff to make sure it makes sense
phi.estim=nks/matrix(rowSums(nks),ncommun,nspp)
plot(phi.true,phi.estim)
nks.true=nks
#export results
setwd('U:\\GIT_models\\git_LDA_MS')
nome='fake data.csv'
colnames(y)=paste('spp',1:nspp,sep='')
rownames(y)=paste('loc',1:nloc,sep='')
write.csv(y,nome,row.names=F)
nome='fake data xmat.csv'
write.csv(xmat,nome,row.names=F)
rm(list=ls(all=TRUE))
library(MCMCpack)
library('Rcpp')
library('RcppArmadillo')
set.seed(33)
#get data
setwd('U:\\GIT_models\\git_LDA_MS')
dat=read.csv('fake data.csv',as.is=T)
xmat=data.matrix(read.csv('fake data xmat.csv',as.is=T))
y=data.matrix(dat)
#basic settings
ncomm=10
ngibbs=1000
nburn=ngibbs/2
#priors
psi=0.01
gamma=0.1
#----------------------------------------------------------
#run LDA no covariates to get initial values
#get functions
setwd('U:\\GIT_models\\git_LDA_abundance')
source('gibbs functions.R')
source('LDA.abundance main function.R')
sourceCpp('aux1.cpp')
res=LDA.abundance(y=y,ncomm=ncomm,ngibbs=ngibbs,nburn=nburn,psi=psi,gamma=gamma)
nloc=nrow(y)
nspp=ncol(y)
array.lsk.init=res$array.lsk
#determine optimal number of groups
nlk=apply(array.lsk.init,c(1,3),sum)
theta=nlk/apply(nlk,1,sum)
par(mfrow=c(1,1),mar=c(3,3,1,1))
boxplot(theta)
ncomm=4
prop=apply(theta>0.8,2,sum,na.rm=T) #see which communities are never above 0.8
which(prop!=0)
cond=prop!=0
ncomm=sum(cond)
#re-distribute individuals within array.lsk.init that are in eliminated communities
array.lsk=array.lsk.init[,,cond]
for (i in 1:nloc){
for (j in 1:nspp){
tmp=array.lsk.init[i,j,!cond]
n=sum(tmp)
if (n>0){
z=rmultinom(1,size=n,prob=rep(1/ncomm,ncomm))
array.lsk[i,j,]=array.lsk[i,j,]+z
}
}
}
#export results
dat1=matrix(array.lsk,nloc*nspp*ncomm,1)
setwd('U:\\GIT_models\\git_LDA_MS')
write.csv(dat1,'array lsk.csv',row.names=F)
rm(list=ls(all=TRUE))
library(MCMCpack)
library('Rcpp')
library('RcppArmadillo')
set.seed(10)
#get data
setwd('U:\\GIT_models\\git_LDA_MS')
dat=read.csv('fake data.csv',as.is=T)
xmat=data.matrix(read.csv('fake data xmat.csv',as.is=T))
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
#get array.lsk
tmp=read.csv('array lsk.csv',as.is=T)
ncomm=4 #this was estimated based on a previous step
array.lsk.init=array(tmp$V1,dim=c(nloc,nspp,ncomm))
rm(list=ls(all=TRUE))
library(MCMCpack)
library('Rcpp')
library('RcppArmadillo')
set.seed(10)
#get data
setwd('U:\\GIT_models\\git_LDA_MS')
dat=read.csv('fake data.csv',as.is=T)
xmat=data.matrix(read.csv('fake data xmat.csv',as.is=T))
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
#get array.lsk
tmp=read.csv('array lsk.csv',as.is=T)
ncomm=length(tmp$V1)/(nspp*ncomm); ncomm
array.lsk.init=array(tmp$V1,dim=c(nloc,nspp,ncomm))
rm(list=ls(all=TRUE))
library(MCMCpack)
library('Rcpp')
library('RcppArmadillo')
set.seed(10)
#get data
setwd('U:\\GIT_models\\git_LDA_MS')
dat=read.csv('fake data.csv',as.is=T)
xmat=data.matrix(read.csv('fake data xmat.csv',as.is=T))
y=data.matrix(dat)
nloc=nrow(y)
nspp=ncol(y)
#get array.lsk
tmp=read.csv('array lsk.csv',as.is=T)
ncomm=length(tmp$V1)/(nspp*nloc); ncomm
array.lsk.init=array(tmp$V1,dim=c(nloc,nspp,ncomm))
#basic settings
ngibbs=1000
nburn=ngibbs/2
#priors
phi.prior=0.01
var.betas=c(10,rep(1,ncol(xmat)-1))
gamma=0.1
#----------------------------------------------------------
#LDA with covariates
#get functions
setwd('U:\\GIT_models\\git_LDA_MS')
source('LDA cov main function.R')
source('LDA cov aux functions.R')
sourceCpp('LDA_cov_aux1_cpp.cpp')
res=gibbs.LDA.cov(ncomm=ncomm,ngibbs=ngibbs,nburn=nburn,y=y,xmat=xmat,
phi.prior=phi.prior,array.lsk.init=array.lsk.init,
var.betas=var.betas)
plot(res$llk,type='l')
plot(res$fmodel,type='l')
plot(res$llk,type='l')
library(MCMCpack)
set.seed(30)
nloc=3000
nspp=100
ncommun=4
#design matrix
xmat=matrix(runif(nloc*ncommun,min=-3,max=3),nloc,ncommun)
#pure sites
tmp=matrix(-3,ncommun,ncommun)
diag(tmp)=3
num1=floor(nloc/ncommun)
for (i in 1:200){
seq1=(ncommun*(i-1)+1):(ncommun*i)
xmat[seq1,]=tmp
}
image(xmat)
xmat=cbind(1,xmat)
#parameters
b0=log(runif(ncommun,min=4,max=7))
betas.true=betas=rbind(b0,diag(1,ncommun))
#get means
media.true=media=exp(xmat%*%betas); range(media)
head(media)
#generate N_lk
par(mfrow=c(1,1),mar=rep(4,4))
nlk=matrix(NA,nloc,ncommun)
for (i in 1:ncommun){
nlk[,i]=rpois(nloc,media[,i])
}
nlk.true=nlk; boxplot(nlk)
z=nlk/apply(nlk,1,sum); apply(z,1,sum); boxplot(z); apply(z,2,range); apply(z>0.9,2,mean)
nl=apply(nlk,1,sum)
hist(nl)
sum(nl)
plot(media,nlk)
#generate phi (assuming that each species is strongly present in a single group)
phi=matrix(0.01,ncommun,nspp)
num=floor(nspp/ncommun)
for (i in 1:nspp){
n=rbinom(1,size=1,prob=0.1)+1
ind=sample(1:ncommun,size=n)
phi[ind,i]=1
}
phi.true=phi=phi/matrix(apply(phi,1,sum),ncommun,nspp)
apply(phi,1,sum)
image(phi[,1:20])
#per species
par(mfrow=c(4,2),mar=rep(1,4))
for (i in 1:(ncommun*2)) plot(phi[,i]/sum(phi[,i]),type='h',ylim=c(0,1))
par(mfrow=c(4,2),mar=rep(1,4))
for (i in 1:ncommun) plot(phi[i,],type='h')
# for (i in 1:nspp){ #add some zeroes
#   ind=sample(1:ncommun,size=1)
#   tmp[ind,i]=runif(1,min=0.5,max=1)
# }
# phi=tmp/matrix(rowSums(tmp),ncommun,nspp) #re-scale to make sure it sums to 1
# round(phi[,1:20],2)
# table(round(phi,2))
unique(rowSums(phi))
phi.true=phi
image(phi)
#generate actual observations y
array.lsk=array(0,dim=c(nloc,nspp,ncommun))
for (i in 1:nloc){
for (k in 1:ncommun){
array.lsk[i,,k]=rmultinom(1,size=nlk[i,k],prob=phi[k,])
}
}
array.lsk.true=array.lsk
y=apply(array.lsk,c(1,2),sum)
nks=t(apply(array.lsk,c(2,3),sum))
image(y)
plot(phi,nks)
#checking if it makes sense
plot(apply(array.lsk,c(1,3),sum),nlk)
lines(c(0,1000),c(0,1000))
#look at stuff to make sure it makes sense
phi.estim=nks/matrix(rowSums(nks),ncommun,nspp)
plot(phi.true,phi.estim)
nks.true=nks
plot(res$llk[1:ngibbs],type='l')
compare1=function(estim,true){
rango=range(c(true,estim))
plot(true,estim,ylim=rango,xlim=rango)
lines(rango,rango,col='red',lwd=2)
}
k=res$betas[ngibbs,]
nparam=ncol(xmat)
k1=matrix(k,nparam,ncomm); round(k1,2)
ordem=rep(NA,ncomm)
for (i in 2:nparam){
ordem[i-1]=which(k1[i,]==max(k1[i,]))
}
round(k1[,ordem],2)
image(k1[,ordem])
#look at nlk
tmp=matrix(res$nlk[ngibbs,],nloc,ncomm);
boxplot(tmp)
compare1(estim=jitter(tmp[,ordem]),true=jitter(nlk.true))
#look at betas
k=matrix(res$betas[ngibbs,],nparam,ncomm)
compare1(estim=k[,ordem],true=betas.true)
tmp=matrix(res$phi[ngibbs,],ncomm,nspp)
tmp1=tmp[ordem,]
compare1(estim=tmp1,true=phi.true)
